--
-- Drop existing table
--
DROP TABLE IF EXISTS foo;
NOTICE:  table "foo" does not exist, skipping
--
-- Create new table foo
--
CREATE TABLE foo(type INTEGER, prod VARCHAR, quantity NUMERIC);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'type' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
--
-- Insert some values
--
INSERT INTO foo VALUES
  (1, 'Table', 100),
  (2, 'Chair', 250),
  (3, 'Bed', 300);
--
-- Select query with grouping sets
--
SELECT type, prod, sum(quantity) s_quant
FROM
(
  SELECT type, prod, quantity
  FROM foo F1
  LIMIT 3
) F2 GROUP BY GROUPING SETS((type, prod), (prod)) ORDER BY type, s_quant;
 type | prod  | s_quant 
------+-------+---------
    1 | Table |     100
    2 | Chair |     250
    3 | Bed   |     300
      | Table |     100
      | Chair |     250
      | Bed   |     300
(6 rows)

--
-- Case for partitioned table
--
--
-- Create new table bar
--
CREATE TABLE pfoo(type INTEGER, prod VARCHAR, quantity NUMERIC)
DISTRIBUTED RANDOMLY
PARTITION BY RANGE (quantity) (
	partition "1" start (0) end (100),
	partition "2" start (100) end (200),
	partition "3" start (200) end (300),
	partition "4" start (300) end (400)
);
NOTICE:  CREATE TABLE will create partition "pfoo_1_prt_1" for table "pfoo"
NOTICE:  CREATE TABLE will create partition "pfoo_1_prt_2" for table "pfoo"
NOTICE:  CREATE TABLE will create partition "pfoo_1_prt_3" for table "pfoo"
NOTICE:  CREATE TABLE will create partition "pfoo_1_prt_4" for table "pfoo"
--
-- Insert some values
--
INSERT INTO pfoo VALUES
  (1, 'Table', 100),
  (2, 'Chair', 250),
  (3, 'Bed', 300);
--
-- Turn off GPORCA
--
set optimizer to off;
--
-- Select query with grouping sets
--
SELECT type, prod, sum(quantity) s_quant
FROM (
	SELECT * FROM pfoo
) AS t
GROUP BY GROUPING SETS((type), (prod))
ORDER BY type, s_quant;
 type | prod  | s_quant 
------+-------+---------
    1 |       |     100
    2 |       |     250
    3 |       |     300
      | Table |     100
      | Chair |     250
      | Bed   |     300
(6 rows)

---
--- Planning for sub-queries that have grouping sets
---
explain (costs off) WITH table1 AS (
	SELECT 2 AS city_id, 5 AS cnt
	UNION ALL
	SELECT 2 AS city_id, 1 AS cnt
	UNION ALL
	SELECT 3 AS city_id, 2 AS cnt
	UNION ALL
	SELECT 3 AS city_id, 7 AS cnt
),
fin AS (
SELECT
	coalesce(country_id, city_id) AS location_id,
	total
FROM (
	SELECT
	1 as country_id,
	city_id,
	sum(cnt) as total
	FROM table1
	GROUP BY GROUPING SETS (1,2)
	) base
)
SELECT *
FROM fin
WHERE location_id = 1;
                                                  QUERY PLAN                                                   
---------------------------------------------------------------------------------------------------------------
 Subquery Scan on base
   Filter: (COALESCE(base.country_id, base.city_id) = 1)
   ->  Append
         ->  HashAggregate
               Group Key: "rollup".city_id, "rollup".prelim_aggref_1, "rollup"."grouping", "rollup"."group_id"
               ->  Subquery Scan on "rollup"
                     ->  GroupAggregate
                           Group Key: table1.city_id, (1)
                           ->  Sort
                                 Sort Key: table1.city_id
                                 ->  Subquery Scan on table1
                                       ->  Append
                                             ->  Result
                                             ->  Result
                                             ->  Result
                                             ->  Result
         ->  HashAggregate
               Group Key: rollup_1.prelim_aggref_1, rollup_1.city_id, rollup_1."grouping", rollup_1."group_id"
               ->  Subquery Scan on rollup_1
                     ->  GroupAggregate
                           Group Key: (1), table1_1.city_id
                           ->  Sort
                                 Sort Key: table1_1.city_id
                                 ->  Subquery Scan on table1_1
                                       ->  Append
                                             ->  Result
                                             ->  Result
                                             ->  Result
                                             ->  Result
 Optimizer: Postgres query optimizer
(30 rows)

--
-- Select constant from GROUPING SETS of multiple empty sets
--
explain (costs off)
select 1 from foo group by grouping sets ((), ());
                      QUERY PLAN                      
------------------------------------------------------
 Repeat
   ->  Aggregate
         ->  Gather Motion 3:1  (slice1; segments: 3)
               ->  Aggregate
                     ->  Seq Scan on foo
 Optimizer: Postgres query optimizer
(6 rows)

select 1 from foo group by grouping sets ((), ());
 ?column? 
----------
        1
        1
(2 rows)

--
-- GROUPING SETS with const in the group by
--
create table foo_gset_const(a int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into foo_gset_const values(0), (1);
-- const and var in the groupint sets
explain (costs off)
select 1, a from foo_gset_const group by grouping sets(1,2);
                                               QUERY PLAN                                                
---------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)
   ->  Append
         ->  GroupAggregate
               Group Key: "rollup".a, "rollup".prelim_aggref_1, "rollup"."grouping", "rollup"."group_id"
               ->  Subquery Scan on "rollup"
                     ->  Sort
                           Sort Key: share0_ref1.a, share0_ref1.col_2, (Grouping), (group_id())
                           ->  Redistribute Motion 3:3  (slice1; segments: 3)
                                 Hash Key: share0_ref1.a, share0_ref1.col_2, (Grouping), group_id()
                                 ->  GroupAggregate
                                       Group Key: share0_ref1.a, share0_ref1.col_2
                                       ->  Sort
                                             Sort Key: share0_ref1.a
                                             ->  Shared Scan (share slice:id 1:0)
                                                   ->  Materialize
                                                         ->  Seq Scan on foo_gset_const
         ->  GroupAggregate
               Group Key: rollup_1.prelim_aggref_1, rollup_1.a, rollup_1."grouping", rollup_1."group_id"
               ->  Subquery Scan on rollup_1
                     ->  Sort
                           Sort Key: share0_ref2.col_2, share0_ref2.a, (Grouping), (group_id())
                           ->  Redistribute Motion 3:3  (slice2; segments: 3)
                                 Hash Key: share0_ref2.col_2, share0_ref2.a, (Grouping), group_id()
                                 ->  GroupAggregate
                                       Group Key: share0_ref2.col_2, share0_ref2.a
                                       ->  Sort
                                             Sort Key: share0_ref2.a
                                             ->  Shared Scan (share slice:id 2:0)
 Optimizer: Postgres query optimizer
(29 rows)

select 1, a from foo_gset_const group by grouping sets(1,2);
 ?column? | a 
----------+---
          | 0
          | 1
        1 |  
(3 rows)

explain (costs off)
select 1, a, count(distinct(a)) from foo_gset_const group by grouping sets(1,2);
                           QUERY PLAN                           
----------------------------------------------------------------
 Append
   ->  GroupAggregate
         Group Key: share0_ref1.a, share0_ref1.col_2
         ->  Gather Motion 3:1  (slice1; segments: 3)
               Merge Key: share0_ref1.a
               ->  Sort
                     Sort Key: share0_ref1.a
                     ->  Shared Scan (share slice:id 1:0)
                           ->  Materialize
                                 ->  Seq Scan on foo_gset_const
   ->  GroupAggregate
         Group Key: share0_ref2.col_2, share0_ref2.a
         ->  Gather Motion 3:1  (slice2; segments: 3)
               Merge Key: share0_ref2.a
               ->  Sort
                     Sort Key: share0_ref2.a
                     ->  Shared Scan (share slice:id 2:0)
 Optimizer: Postgres query optimizer
(18 rows)

select 1, a, count(distinct(a)) from foo_gset_const group by grouping sets(1,2);
 ?column? | a | count 
----------+---+-------
          | 0 |     1
          | 1 |     1
        1 |   |     2
(3 rows)

explain (costs off)
select * from (select 1 as x, a, sum(a) as sum from foo_gset_const group by grouping sets(1, 2)) ss where x = 1 and sum = 1;
                                                  QUERY PLAN                                                   
---------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice3; segments: 3)
   ->  Subquery Scan on ss
         Filter: ((ss.x = 1) AND (ss.sum = 1))
         ->  Append
               ->  HashAggregate
                     Group Key: "rollup".a, "rollup".prelim_aggref_1, "rollup"."grouping", "rollup"."group_id"
                     ->  Subquery Scan on "rollup"
                           ->  Redistribute Motion 3:3  (slice1; segments: 3)
                                 Hash Key: share0_ref1.a, share0_ref1.col_2, (Grouping), group_id()
                                 ->  GroupAggregate
                                       Group Key: share0_ref1.a, share0_ref1.col_2
                                       ->  Sort
                                             Sort Key: share0_ref1.a
                                             ->  Shared Scan (share slice:id 1:0)
                                                   ->  Materialize
                                                         ->  Seq Scan on foo_gset_const
               ->  HashAggregate
                     Group Key: rollup_1.prelim_aggref_1, rollup_1.a, rollup_1."grouping", rollup_1."group_id"
                     ->  Subquery Scan on rollup_1
                           ->  Redistribute Motion 3:3  (slice2; segments: 3)
                                 Hash Key: share0_ref2.col_2, share0_ref2.a, (Grouping), group_id()
                                 ->  GroupAggregate
                                       Group Key: share0_ref2.col_2, share0_ref2.a
                                       ->  Sort
                                             Sort Key: share0_ref2.a
                                             ->  Shared Scan (share slice:id 2:0)
 Optimizer: Postgres query optimizer
(27 rows)

select * from (select 1 as x, a, sum(a) as sum from foo_gset_const group by grouping sets(1, 2)) ss where x = 1 and sum = 1;
 x | a | sum 
---+---+-----
 1 |   |   1
(1 row)

-- only const in the groupint sets
explain (costs off)
select '' ,'' ,count(1) from foo_gset_const group by rollup(1,2) ;
                                                                         QUERY PLAN                                                                          
-------------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3)
   ->  GroupAggregate
         Group Key: partial_aggregation.prelim_aggref_1, partial_aggregation.prelim_aggref_2, partial_aggregation."grouping", partial_aggregation."group_id"
         ->  Subquery Scan on partial_aggregation
               ->  Sort
                     Sort Key: "rollup".prelim_aggref_1, "rollup".prelim_aggref_1, (Grouping)
                     ->  Redistribute Motion 3:3  (slice1; segments: 3)
                           Hash Key: "rollup".prelim_aggref_1, "rollup".prelim_aggref_1
                           ->  GroupAggregate
                                 Group Key: "rollup"."grouping", "rollup"."group_id", "rollup".prelim_aggref_1, "rollup".prelim_aggref_2
                                 ->  Subquery Scan on "rollup"
                                       ->  GroupAggregate
                                             Group Key: rollup_1.prelim_aggref_1, rollup_1."grouping", rollup_1."group_id", rollup_1.prelim_aggref_2
                                             ->  Subquery Scan on rollup_1
                                                   ->  GroupAggregate
                                                         Group Key: ''::text, ''::text
                                                         ->  Seq Scan on foo_gset_const
 Optimizer: Postgres query optimizer
(18 rows)

select '' ,'' ,count(1) from foo_gset_const group by rollup(1,2) ;
 ?column? | ?column? | count 
----------+----------+-------
          |          |     2
          |          |     2
          |          |     2
(3 rows)

explain (costs off)
select '' ,'' ,count(distinct(a)) from foo_gset_const group by rollup(1,2) ;
                            QUERY PLAN                            
------------------------------------------------------------------
 Append
   ->  GroupAggregate
         Group Key: share0_ref1.col_2, share0_ref1.col_3
         ->  Shared Scan (share slice:id 0:0)
               ->  Materialize
                     ->  Gather Motion 3:1  (slice1; segments: 3)
                           ->  Seq Scan on foo_gset_const
   ->  GroupAggregate
         Group Key: share0_ref2.col_2, share0_ref2.col_3
         ->  Shared Scan (share slice:id 0:0)
   ->  GroupAggregate
         Group Key: share0_ref3.col_2, share0_ref3.col_3
         ->  Shared Scan (share slice:id 0:0)
 Optimizer: Postgres query optimizer
(14 rows)

select '' ,'' ,count(distinct(a)) from foo_gset_const group by rollup(1,2) ;
 ?column? | ?column? | count 
----------+----------+-------
          |          |     2
          |          |     2
          |          |     2
(3 rows)

drop table foo_gset_const;
--
-- GROUPING SETS with DQA should not have unnecessary sort nodes
--
create table foo_gset_dqa(i int, j int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'i' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into foo_gset_dqa values(1,1);
insert into foo_gset_dqa values(2,1);
explain (costs off)
select i, j, count(distinct j) from foo_gset_dqa GROUP BY grouping sets((i), (j));
                          QUERY PLAN                          
--------------------------------------------------------------
 Append
   ->  GroupAggregate
         Group Key: share0_ref1.j, share0_ref1.i
         ->  Gather Motion 3:1  (slice1; segments: 3)
               Merge Key: share0_ref1.j, share0_ref1.i
               ->  Sort
                     Sort Key: share0_ref1.j, share0_ref1.i
                     ->  Shared Scan (share slice:id 1:0)
                           ->  Materialize
                                 ->  Seq Scan on foo_gset_dqa
   ->  GroupAggregate
         Group Key: share0_ref2.i, share0_ref2.j
         ->  Gather Motion 3:1  (slice2; segments: 3)
               Merge Key: share0_ref2.i, share0_ref2.j
               ->  Sort
                     Sort Key: share0_ref2.i, share0_ref2.j
                     ->  Shared Scan (share slice:id 2:0)
 Optimizer: Postgres query optimizer
(18 rows)

select i, j, count(distinct j) from foo_gset_dqa GROUP BY grouping sets((i), (j));
 i | j | count 
---+---+-------
   | 1 |     1
 1 |   |     1
 2 |   |     1
(3 rows)

drop table foo_gset_dqa;
--
-- Reset settings
--
reset optimizer;
